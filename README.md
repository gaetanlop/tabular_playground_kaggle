# Tabular_playground_kaggle

## Complete roadmap on how I worked on this competition

* 11/02: Hyperparameter tuning using Optuna
* 12/02: Decision Tree/ XGBoost hyperparameter tuning
* 13/02: Practical implementation of XGBoost and Optuna
* 15/02: Shap Values Theory + practical Implementation
* 16/02: Tried some Feature Engineering ideas with no success + 10 folds did not improve the model
* 17/02: lgbm theory + implementation using optuna
* 18/02: XGBoost Optuna cross val didnot work + cat boost implementation
* 19/02: theory + lgbm optimization
* 20/02: lgbm theory + implementation of how to hyper tune lgbm

To do DAE!
