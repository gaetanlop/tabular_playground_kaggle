# Tabular_playground_kaggle

## Complete roadmap on how I worked on this competition

* 11/02: Hyperparameter tuning using Optuna
* 12/02: Decision Tree/ XGBoost hyperparameter tuning
* 13/02: Practical implementation of XGBoost and Optuna
* 15/02: Shap Values Theory + practical Implementation
* 16/02: Tried some Feature Engineering ideas with no success + 10 folds did not improve the model
* 17/02: lgbm theory + implementation using optuna
* 18/02: XGBoost Optuna cross val didnot work + cat boost implementation
* 19/02: theory + lgbm optimization

=> Theory + step by step optimization xgboost lgbm https://www.kaggle.com/rmiperrier/step-by-step-lgb-optimization
